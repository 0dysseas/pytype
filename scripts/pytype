#!/usr/bin/python2.7
"""Tool for inferring types from Python programs.

'pytype' is a tool for generating pytd from Python programs.

Usage:
  pytype [flags] file.py
"""

import logging
import optparse
import os
import sys
import traceback

from pytype import infer
from pytype.pytd import optimize
from pytype.pytd import pytd
from pytype.pytd import utils as pytd_utils


log = logging.getLogger(__name__)

LOG_LEVELS = [logging.CRITICAL, logging.ERROR, logging.WARNING,
              logging.INFO, logging.DEBUG]


# The input files will typically end with ".py".

# There may also be input files that end with ".pytd" -- these are PyTD and are
# used to supplement function annotations (e.g., for Python2 source) -- they are
# similar to PEP 484 "stubs" but with a different syntax; and we'll eventually
# switch to PEP 484 syntax.

# TODO(pludemann): Add this to the pytype documentation:
# TODO(pludemann): 2017-07-14: Merging .py and .pytd inputs not yet implemented
#
# If you use .pytd for output files and also have .pytd inputs, you should be
# careful to distinguish the two usages, and consider using a different file
# extension for output from pytype (e.g., .pytd-gen).  The output from pytype is
# "complete" ... that is, it is made up of a combination of the function
# annotations and inferences, and has an entry for every function, method,
# global variable. If you have hand-crafted a .pytd, it does not need to be
# "complete" but will be used to specify type annotations that pytype will only
# verify and won't try to infer.


DEFAULT_PYTD_IMPORT_EXT = ".pytd"


def _parse_options(args):
  """Use optparse to parse command line options."""
  o = optparse.OptionParser(
      description="Infer/check types in a Python module")
  o.set_defaults(optimize=True)
  o.set_defaults(api=True)
  o.add_option(
      "-o", "--output", type="string", action="store",
      dest="output", default=None,
      help=("Output file (default: stdout), if --src_out not given. "
            "Use '-' or '' for stdout."))
  # TODO(pludemann): instead of --src_out, allow the command to take a list
  #                  of pairs:
  #                    pytype in1:out1 in2:out2
  o.add_option(
      "--src_out", type="string", action="store",
      dest="src_out", default=None,
      help=("A '%s'-separated list of '%s'-separated pairs, each of "
            "which is a source file (.py) and a pytd output (.pytd). "
            "NOTE: this options may go away and be replaced by "
            "'in:out' filenames on the command line." % (",", os.pathsep)))
  o.add_option(
      "-V", "--python_version", type="string", action="store",
      dest="python_version", default="2.7",
      help=("Python version to emulate (\"major.minor\", e.g. \"2.7\")"))
  o.add_option(
      "-v", "--verbosity", type="int", action="store",
      dest="verbosity", default=1,
      help=("Set logging verbosity: "
            "-1=quiet, 0=fatal, 1=error (default), 2=warn, 3=info, 4=debug"))
  o.add_option(
      "-O", "--optimize", action="store_true",
      dest="optimize",
      help=("Optimize generated pytd (default)."))
  o.add_option(
      "-R", "--raw", action="store_false",
      dest="optimize",
      help=("Do not optimize generated pytd"))
  o.add_option(
      "-A", "--api", action="store_true",
      dest="api",
      help=("Analyze all functions and classes, "
            "also those not called from anywhere (default)."))
  o.add_option(
      "-m", "--main", action="store_false",
      dest="api",
      help=("Only analyze the main method and everything called from it"))
  o.add_option(
      "-S", "--structural", action="store_true",
      dest="structural", default=False,
      help=("Analyze all functions and classes, also those not called from "
            "anywhere. Output the result in structural form."))
  o.add_option(
      "-K", "--keep-unknowns", action="store_false",
      dest="solve_unknowns", default=True,
      help=("Keep 'unknown' classes generated during the first analysis pass."))
  o.add_option(
      "--no-native-builtins", action="store_false",
      dest="run_builtins", default=True,
      help=("Run the program without the native Python builtins preloaded."))
  o.add_option(
      "-B", "--builtins", type="string", action="store",
      dest="pybuiltins_filename", default=None,
      help=("Use user-supplied custom definition of __builtin__.py "
            "(for debugging). This should be an absolute file name; "
            "if it is not an absolute file name, it is resolved using "
            "--pythonpath. "
            "The default resolves to pytd/builtins/__builtin__.py. "
            "Note that this does not affect the PyTD for builtins, which "
            "is always in pytd/builtins/__builtin__.pytd."))
  o.add_option(
      "--output-cfg", type="string", action="store",
      dest="output_cfg", default=None,
      help="Output control flow graph as SVG.")
  o.add_option(
      "--output-typegraph", type="string", action="store",
      dest="output_typegraph", default=None,
      help="Output typegraph as SVG.")
  o.add_option(
      "--output-pseudocode", type="string", action="store",
      dest="output_pseudocode", default=None,
      help="Output pseudo code.")
  o.add_option(
      "-r", "--reverse-operators", action="store_true",
      dest="reverse_operators", default=False,
      help=("Enable support for Python reverse "
            "operator overloading (__radd__ etc.)"))
  o.add_option(
      "-N", "--no-cache-unknowns", action="store_false",
      dest="cache_unknowns", default=True,
      help="Do slower and more precise processing of unknown types.")
  o.add_option(
      "--no-skip-calls", action="store_false",
      dest="skip_repeat_calls", default=True,
      help=("Don't reuse the results of previous function calls."))
  o.add_option(
      "--irascible", type="int", action="store",
      dest="irascible", default=None,
      help="Non-zero return code: 0=critical, 1=error, 2=warn, ...")
  o.add_option(
      "--pythonpath", type="string", action="store",
      dest="pythonpath", default="",
      help=("Directories for reading dependencies - a list of paths "
            "separated by '%s'. The files must have been "
            "generated by running pytype on depdencies of the file(s) "
            "being analyzed. That is, if an input .py file has an "
            "'import path.to.foo', and pytype has already been run with "
            "'pytype path.to.foo.py -o $OUTDIR/path/to/foo%s', then "
            "pytype should be invoked with $OUTDIR in --pythonpath.") % (
                os.pathsep, DEFAULT_PYTD_IMPORT_EXT))
  o.add_option(
      "--find_pytd_import_ext", type="string", action="store",
      dest="find_pytd_import_ext",
      default=DEFAULT_PYTD_IMPORT_EXT,
      help=("Pattern appended to filename when looking up import PyTD files in "
            "pythonpath. Supports '*' and [...] expansions. "
            "Default is '%s'.") % DEFAULT_PYTD_IMPORT_EXT)
  o.add_option(
      "--import_drop_prefixes", type="string", action="store",
      dest="import_drop_prefixes",
      default="",
      help=("List of prefixes to be dropped when resolving module names "
            "in import statements. The items are separated by '%s'. "
            "The individual items may contain '.'. "
            "The intended usecase is for when you're running tests in "
            "a directory structure that starts below the root module in "
            "your module names.") % os.pathsep)
  # MOE:strip_line TODO(pludemann): remove when Bazel integration done:
  o.add_option(
      "--warn_on_exception", action="store_true",
      dest="warn_on_exception", default=False,
      help=("Temporary flag that turns exceptions into warnings. "
            "Default is for exceptions to be critical errors."))

  options, input_filenames = o.parse_args(args)
  return options, input_filenames


class TrackLevel(logging.Handler):

  def __init__(self):
    super(TrackLevel, self).__init__()
    self.clear()

  def clear(self):
    self.max_level = logging.NOTSET

  def emit(self, record):
    self.max_level = max(self.max_level, record.levelno)


def _file_contents_equals(output_filename, contents):
  """Return True if file exists and has contents."""
  if os.path.isfile(output_filename):
    with open(output_filename, "rb") as fi:
      return fi.read() == contents
  else:
    return False


def _initialize_logging(options, log_level_tracker):
  """Set up appropriate logging verbosity + tracking max log severity."""
  if options.verbosity >= 0:
    if options.verbosity >= len(LOG_LEVELS):
      print >> sys.stderr, "Invalid verbosity: %d" % options.verbosity
      sys.exit(1)
    logging.basicConfig(level=LOG_LEVELS[options.verbosity])
  else:
    # "verbosity=-1" can be used to disable all logging, so configure logging
    # accordingly.
    logging.basicConfig(level=logging.CRITICAL + 1)
  logging.getLogger().addHandler(log_level_tracker)


def _initialize_filenames_and_output(options, input_filenames):
  """Figure out the input(s) and output(s).

  Calls sys.exit(1) if there's an error in the options or input_filenames.

  Args:
    options: from command line
    input_filenames: any bare filename(s) on the command line
  Returns:
    list of (input_filename, output_filename) pairs where output_filename
    is None if derived input_filename using the command options.
  """
  if options.src_out:
    if input_filenames:
      print >> sys.stderr, "Must not specify both filenames and --out_str"
      sys.exit(1)
    else:
      src_out_split = options.src_out.split(",")
      src_out = [so.split(os.pathsep) for so in src_out_split]
      for i, so in enumerate(src_out):
        if len(so) != 2 or not all(so):
          print >> sys.stderr, ("Item #%d in --src_out is not a pair of non"
                                "empty file names separated by '%s': '%s'" %
                                (i + 1, os.pathsep, src_out_split[i]))
          sys.exit(1)
  else:
    if len(input_filenames) < 1:
      print >> sys.stderr, "Need at least one filename or --src_out."
      sys.exit(1)
    elif len(input_filenames) >= 2:
      # TODO(pludemann): see comment with --src_out
      print >> sys.stderr, ("Analyzing multiple files not supported - "
                            "use --src_out")
      print >> sys.stderr, " ".join(input_filenames)
      sys.exit(1)
    src_out = [(input_filenames[0], options.output)]

  if (options.irascible is not None and
      options.irascible < -1 or options.irascible > len(LOG_LEVELS)):
    print >> sys.stderr, "Invalid irascible: %d" % options.irascible
    sys.exit(1)

  return src_out


def process_one_file(input_filename, output_filename,
                     options, pythonpath, import_drop_prefixes):
  """Run the inferencer on one file, producing output.

  Args:
    input_filename: name of the file to process
    output_filename: name of the file for writing the output. If this is None,
                     then the options are used to determine where to write the
                     output.
    options: the command-line flags (processed)
    pythonpath: from --pythonpath
    import_drop_prefixes: from --import_drop_prefixes

  Raises:
    ValueError: for some invalid options
  """
  with open(input_filename, "r") as fi:
    src = fi.read()

  python_version = tuple(map(int, options.python_version.split(".")))
  if len(python_version) != 2:
    log.error("--python_version must be <major>.<minor>")
    sys.exit(1)

  # TODO(pludemann): sanity check options.find_pytd_import_ext.startswith(".")
  #                  for something like .pytd or <*>.pytd

  # MOE:begin_strip
  # Why does the following test sometimes fail on Forge?
  # MOE:end_strip
  # This test is not 100% reliable, so turn off for now.
  if False:
    for d in pythonpath:
      if not os.path.isdir(d):
        raise ValueError(
            "--pythonpath item is not a directory: '%s stat(%s) lstat(%s)" %
            (d, os.stat(d), os.lstat(d)))

  try:
    mod = infer.infer_types(
        src,
        python_version=python_version,
        filename=input_filename,
        run_builtins=options.run_builtins,
        pybuiltins_filename=options.pybuiltins_filename,
        pythonpath=pythonpath,
        find_pytd_import_ext=options.find_pytd_import_ext,
        import_drop_prefixes=import_drop_prefixes,
        deep=options.api or options.structural,
        solve_unknowns=options.solve_unknowns or options.api,
        output_cfg=options.output_cfg,
        output_typegraph=options.output_typegraph,
        output_pseudocode=options.output_pseudocode,
        reverse_operators=options.reverse_operators,
        cache_unknowns=options.cache_unknowns,
        skip_repeat_calls=options.skip_repeat_calls)
  except Exception as e:
    log_exc = log.warn if options.warn_on_exception else log.critical
    exc_msg = str(e) or e.__doc__ or repr(e)
    log_exc("***Caught exception: %s", exc_msg, exc_info=True)
    result = ("# Caught error in pytype: " + exc_msg + "\n# " +
              "\n# ".join(traceback.format_exc().splitlines()))
  else:
    if options.optimize:
      mod = optimize.Optimize(mod,
                              # TODO(kramm): Add FLAGs for these
                              lossy=False,
                              use_abcs=False,
                              max_union=7,
                              remove_mutable=False)
      log.info("=========== PyTD optimized =============")
    else:
      log.info("=========== PyTD =============")
    mod = pytd_utils.CanonicalOrdering(mod, sort_signatures=True)
    log.info("\n%s", pytd.Print(mod))
    log.info("========================================")

    result = pytd.Print(mod)
    if not result.endswith("\n"):  # TODO(pludemann): fix this hack
      result += "\n"

  if output_filename == "-" or not output_filename:
    sys.stdout.write(result)
  else:
    with open(output_filename, "w") as fi:
      fi.write(result)


def main(argv):
  log_level_tracker = TrackLevel()
  options, input_filenames = _parse_options(argv)
  unused_executable = input_filenames.pop(0)

  _initialize_logging(options, log_level_tracker)

  src_out = _initialize_filenames_and_output(options, input_filenames)
  # TODO(pludemann): maybe select __init__.py items and put them first
  #                  in the list? For now, just process in given order

  # Do *not* apply os.path.abspath here because we could be in a symlink tree
  # and bad things happen if you go to relative directories.
  # MOE:begin_strip
  # Note that you should not do os.path.abspath(f) below; it will probably fail
  # on Forge because of the symlink tree pointing into the cache:
  # MOE:end_strip

  pythonpath = [f for f in options.pythonpath.split(os.pathsep) if f]

  import_drop_prefixes = [
      p for p in options.import_drop_prefixes.split(os.pathsep) if p]

  log.info("Process all: %s", src_out)
  for input_filename, output_filename in src_out:
    log.info("Process [1] %s => %s", input_filename, output_filename)
    process_one_file(input_filename, output_filename,
                     options, pythonpath, import_drop_prefixes)

  if len(src_out) > 1:
    # Do it once more, using any outputs that were produced the first time
    # TODO(pludemann): this is a moderately awful hack: it ensures that any
    #                  multually-dependent generated .pytd files have
    #                  been created, so any further import errors are
    #                  real import errors.
    log.info("Re-processing multiple files (%d)", len(src_out))
    log_level_tracker.clear()
    for input_filename, output_filename in src_out:
      log.info("Process [2] %s => %s", input_filename, output_filename)
      process_one_file(input_filename, output_filename,
                       options, pythonpath, import_drop_prefixes)

  if (options.irascible is not None and
      log_level_tracker.max_level >= LOG_LEVELS[options.irascible]):
    log.critical("Maximum log message %s >= %s",
                 logging.getLevelName(log_level_tracker.max_level),
                 logging.getLevelName(LOG_LEVELS[options.irascible]))
    sys.exit(1)


if __name__ == "__main__":
  main(sys.argv)
