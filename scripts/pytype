#!/usr/bin/python2.7
"""Tool for inferring types from Python programs.

'pytype' is a tool for generating pytd from Python programs.

Usage:
  pytype [flags] file.py
"""

import logging
import optparse
import os
import sys
import traceback

from pytype import errors
from pytype import infer
from pytype.pytd import optimize
from pytype.pytd import pytd
from pytype.pytd import utils as pytd_utils


log = logging.getLogger(__name__)

LOG_LEVELS = [logging.CRITICAL, logging.ERROR, logging.WARNING,
              logging.INFO, logging.DEBUG]


# The input files will typically end with ".py".

# There may also be input files that end with ".pytd" -- these are PyTD and are
# used to supplement function annotations (e.g., for Python2 source) -- they are
# similar to PEP 484 "stubs" but with a different syntax; and we'll eventually
# switch to PEP 484 syntax.

# TODO(pludemann): Add this to the pytype documentation:
# TODO(pludemann): 2017-07-14: Merging .py and .pytd inputs not yet implemented
#
# If you use .pytd for output files and also have .pytd inputs, you should be
# careful to distinguish the two usages, and consider using a different file
# extension for output from pytype (e.g., .pytd-gen).  The output from pytype is
# "complete" ... that is, it is made up of a combination of the function
# annotations and inferences, and has an entry for every function, method,
# global variable. If you have hand-crafted a .pytd, it does not need to be
# "complete" but will be used to specify type annotations that pytype will only
# verify and won't try to infer.


DEFAULT_PYTD_IMPORT_EXT = ".pytd"


def _parse_options(args):
  """Use optparse to parse command line options."""
  o = optparse.OptionParser(
      usage="usage: %prog [options] input1:output1 [input2:output2 [...]]",
      description="Infer/check types in a Python module")
  o.set_defaults(optimize=True)
  o.set_defaults(api=True)
  o.add_option(
      "-o", "--output", type="string", action="store",
      dest="output", default=None,
      help=("Output file (default: stdout). Only allowed if only one input."
            "Use '-' or '' for stdout."))
  o.add_option(
      "-V", "--python_version", type="string", action="store",
      dest="python_version", default="2.7",
      help=("Python version to emulate (\"major.minor\", e.g. \"2.7\")"))
  o.add_option(
      "-v", "--verbosity", type="int", action="store",
      dest="verbosity", default=1,
      help=("Set logging verbosity: "
            "-1=quiet, 0=fatal, 1=error (default), 2=warn, 3=info, 4=debug"))
  o.add_option(
      "-O", "--optimize", action="store_true",
      dest="optimize",
      help=("Optimize generated pytd (default)."))
  o.add_option(
      "-R", "--raw", action="store_false",
      dest="optimize",
      help=("Do not optimize generated pytd"))
  o.add_option(
      "-A", "--api", action="store_true",
      dest="api",
      help=("Analyze all functions and classes, "
            "also those not called from anywhere (default)."))
  o.add_option(
      "-m", "--main", action="store_false",
      dest="api",
      help=("Only analyze the main method and everything called from it"))
  o.add_option(
      "-c", "--check", action="store_true",
      dest="check",
      help=("Verify against existing \"output\" pytd files."))
  o.add_option(
      "-S", "--structural", action="store_true",
      dest="structural", default=False,
      help=("Analyze all functions and classes, also those not called from "
            "anywhere. Output the result in structural form."))
  o.add_option(
      "-K", "--keep-unknowns", action="store_false",
      dest="solve_unknowns", default=True,
      help=("Keep 'unknown' classes generated during the first analysis pass."))
  o.add_option(
      "--no-native-builtins", action="store_false",
      dest="run_builtins", default=True,
      help=("Run the program without the native Python builtins preloaded."))
  o.add_option(
      "-B", "--builtins", type="string", action="store",
      dest="pybuiltins_filename", default=None,
      help=("Use user-supplied custom definition of __builtin__.py "
            "(for debugging). This should be an absolute file name; "
            "if it is not an absolute file name, it is resolved using "
            "--pythonpath. "
            "The default resolves to pytd/builtins/__builtin__.py. "
            "Note that this does not affect the PyTD for builtins, which "
            "is always in pytd/builtins/__builtin__.pytd."))
  o.add_option(
      "--output-cfg", type="string", action="store",
      dest="output_cfg", default=None,
      help="Output control flow graph as SVG.")
  o.add_option(
      "--output-typegraph", type="string", action="store",
      dest="output_typegraph", default=None,
      help="Output typegraph as SVG.")
  o.add_option(
      "--output-pseudocode", type="string", action="store",
      dest="output_pseudocode", default=None,
      help="Output pseudo code.")
  o.add_option(
      "-r", "--reverse-operators", action="store_true",
      dest="reverse_operators", default=False,
      help=("Enable support for Python reverse "
            "operator overloading (__radd__ etc.)"))
  o.add_option(
      "-N", "--no-cache-unknowns", action="store_false",
      dest="cache_unknowns", default=True,
      help="Do slower and more precise processing of unknown types.")
  o.add_option(
      "--no-skip-calls", action="store_false",
      dest="skip_repeat_calls", default=True,
      help=("Don't reuse the results of previous function calls."))
  o.add_option(
      "--irascible", type="int", action="store",
      dest="irascible", default=None,
      help="Non-zero return code: 0=critical, 1=error, 2=warn, ...")
  o.add_option(
      "--pythonpath", type="string", action="store",
      dest="pythonpath", default="",
      help=("Directories for reading dependencies - a list of paths "
            "separated by '%s'. The files must have been "
            "generated by running pytype on dependencies of the file(s) "
            "being analyzed. That is, if an input .py file has an "
            "'import path.to.foo', and pytype has already been run with "
            "'pytype path.to.foo.py -o $OUTDIR/path/to/foo%s', then "
            "pytype should be invoked with $OUTDIR in --pythonpath.") % (
                os.pathsep, DEFAULT_PYTD_IMPORT_EXT))
  o.add_option(
      "--find_pytd_import_ext", type="string", action="store",
      dest="find_pytd_import_ext",
      default=DEFAULT_PYTD_IMPORT_EXT,
      help=("Pattern appended to filename when looking up import PyTD files in "
            "pythonpath. Supports '*' and [...] expansions. "
            "Default is '%s'.") % DEFAULT_PYTD_IMPORT_EXT)
  o.add_option(
      "--import_drop_prefixes", type="string", action="store",
      dest="import_drop_prefixes",
      default="",
      help=("List of prefixes to be dropped when resolving module names "
            "in import statements. The items are separated by '%s'. "
            "The individual items may contain '.'. "
            "The intended usecase is for when you're running tests in "
            "a directory structure that starts below the root module in "
            "your module names.") % os.pathsep)
  # MOE:strip_line TODO(pludemann): remove when Bazel integration is done:
  o.add_option(
      "--warn_on_exception", action="store_true",
      dest="warn_on_exception", default=False,
      help=("Temporary flag that turns exceptions into warnings. "
            "Default is for exceptions to be critical errors."))
  # MOE:strip_line TODO(pludemann): remove when Bazel intergration is done:
  o.add_option(
      "--import_error_is_fatal", action="store_true",
      dest="import_error_is_fatal", default=False,
      help=("Temporary flag that turns load errors (typically a missing "
            ".pytd file) into critical errors."))

  options, input_filenames = o.parse_args(args)
  return options, input_filenames


class TrackLevel(logging.Handler):

  def __init__(self):
    super(TrackLevel, self).__init__()
    self.clear()

  def clear(self):
    self.max_level = logging.NOTSET

  def emit(self, record):
    self.max_level = max(self.max_level, record.levelno)


def _file_contents_equals(output_filename, contents):
  """Return True if file exists and has contents."""
  if os.path.isfile(output_filename):
    with open(output_filename, "rb") as fi:
      return fi.read() == contents
  else:
    return False


def _initialize_logging(options, log_level_tracker):
  """Set up appropriate logging verbosity + tracking max log severity."""
  if options.verbosity >= 0:
    if options.verbosity >= len(LOG_LEVELS):
      print >> sys.stderr, "Invalid verbosity: %d" % options.verbosity
      sys.exit(1)
    logging.basicConfig(level=LOG_LEVELS[options.verbosity])
  else:
    # "verbosity=-1" can be used to disable all logging, so configure logging
    # accordingly.
    logging.basicConfig(level=logging.CRITICAL + 1)
  logging.getLogger().addHandler(log_level_tracker)


def _initialize_filenames_and_output(options, input_filenames):
  """Figure out the input(s) and output(s).

  Calls sys.exit(1) if there's an error in the options or input_filenames.

  Args:
    options: from command line
    input_filenames: any bare filename(s) on the command line
  Returns:
    list of (input_filename, output_filename) pairs where output_filename
    is None if derived input_filename using the command options.
  """
  if not input_filenames:
    print >> sys.stderr, "Need at least one filename."
    sys.exit(1)
  if len(input_filenames) > 1 and options.output:
    print >> sys.stderr, "-o only allowed for single input"
    sys.exit(1)

  src_out = []
  for item in input_filenames:
    split = item.split(os.pathsep)
    if len(split) != 2:
      if len(split) == 1 and len(input_filenames) == 1:
        # special case: For single input, you're allowed to use
        # pytype infile -o outfile.
        src_out.append((item, options.output))
      else:
        print >> sys.stderr, ("Argument %r is not a pair of non"
                              "empty file names separated by %r" %
                              (item, os.pathsep))
        sys.exit(1)
    else:
      src_out.append(split)

  if (options.irascible is not None and
      options.irascible < -1 or options.irascible > len(LOG_LEVELS)):
    print >> sys.stderr, "Invalid irascible: %d" % options.irascible
    sys.exit(1)

  return src_out


def check_pytd(input_filename, output_filename, options, pythonpath,
               import_drop_prefixes, python_version, errorlog):
  with open(input_filename, "r") as fi:
    py_src = fi.read()
  with open(output_filename, "r") as fi:
    pytd_src = fi.read()
  return infer.check_types(
      py_src,
      pytd_src,
      py_filename=input_filename,
      pytd_filename=output_filename,
      python_version=python_version,
      errorlog=errorlog,
      run_builtins=options.run_builtins,
      pybuiltins_filename=options.pybuiltins_filename,
      pythonpath=pythonpath,
      find_pytd_import_ext=options.find_pytd_import_ext,
      import_drop_prefixes=import_drop_prefixes,
      reverse_operators=options.reverse_operators,
      cache_unknowns=options.cache_unknowns,
      skip_repeat_calls=options.skip_repeat_calls,
      import_error_is_fatal=options.import_error_is_fatal)


def generate_pytd(input_filename, output_filename, options, pythonpath,
                  import_drop_prefixes, python_version, errorlog):
  """Run the inferencer on one file, producing output.

  Args:
    input_filename: name of the file to process
    output_filename: name of the file for writing the output. If this is None,
                     then the options are used to determine where to write the
                     output.
    options: the command-line flags (processed)
    pythonpath: from --pythonpath
    import_drop_prefixes: from --import_drop_prefixes
    python_version: A tuple of length 2. (major, minor)
    errorlog: Where to put error messages. Instance or ErrorLog.

  Returns:
    The pytd AST.

  Raises:
    ValueError: for some invalid options
  """
  with open(input_filename, "r") as fi:
    src = fi.read()

  # TODO(pludemann): sanity check options.find_pytd_import_ext.startswith(".")
  #                  for something like .pytd or <*>.pytd

  mod = None
  try:
    mod = infer.infer_types(
        src,
        python_version=python_version,
        errorlog=errorlog,
        filename=input_filename,
        run_builtins=options.run_builtins,
        pybuiltins_filename=options.pybuiltins_filename,
        pythonpath=pythonpath,
        find_pytd_import_ext=options.find_pytd_import_ext,
        import_drop_prefixes=import_drop_prefixes,
        deep=options.api or options.structural,
        solve_unknowns=options.solve_unknowns or options.api,
        output_cfg=options.output_cfg,
        output_typegraph=options.output_typegraph,
        output_pseudocode=options.output_pseudocode,
        reverse_operators=options.reverse_operators,
        cache_unknowns=options.cache_unknowns,
        skip_repeat_calls=options.skip_repeat_calls,
        import_error_is_fatal=options.import_error_is_fatal)
  except Exception as e:  # pylint: disable=broad-except
    if options.warn_on_exception:
      log.warn("***Caught exception: %s", str(e), exc_info=True)
      result = ("# Caught error in pytype: " + str(e) + "\n# " +
                "\n# ".join(traceback.format_exc().splitlines()))
    else:
      raise
  else:
    if options.optimize:
      mod = optimize.Optimize(mod,
                              # TODO(kramm): Add FLAGs for these
                              lossy=False,
                              use_abcs=False,
                              max_union=7,
                              remove_mutable=False)
      log.info("=========== PyTD optimized =============")
    else:
      log.info("=========== PyTD =============")
    mod = pytd_utils.CanonicalOrdering(mod, sort_signatures=True)
    log.info("\n%s", pytd.Print(mod))
    log.info("========================================")

    result = pytd.Print(mod)
    if not result.endswith("\n"):  # TODO(pludemann): fix this hack
      result += "\n"

  if output_filename == "-" or not output_filename:
    sys.stdout.write(result)
  else:
    with open(output_filename, "w") as fi:
      fi.write(result)
  return mod


def process_one_file(input_filename, output_filename,
                     options, pythonpath, import_drop_prefixes, python_version):
  errorlog = errors.ErrorLog()
  if options.check:
    result = check_pytd(input_filename, output_filename, options, pythonpath,
                        import_drop_prefixes, python_version, errorlog)
  else:
    result = generate_pytd(input_filename, output_filename, options, pythonpath,
                           import_drop_prefixes, python_version, errorlog)
  errorlog.print_to_stderr()
  return result


def main(argv):
  log_level_tracker = TrackLevel()
  options, input_filenames = _parse_options(argv)
  unused_executable = input_filenames.pop(0)

  _initialize_logging(options, log_level_tracker)

  src_out = _initialize_filenames_and_output(options, input_filenames)
  # TODO(pludemann): maybe select __init__.py items and put them first
  #                  in the list? For now, just process in given order

  # Do *not* apply os.path.abspath here because we could be in a symlink tree
  # and bad things happen if you go to relative directories.
  # MOE:begin_strip
  # Note that you should not do os.path.abspath(f) below; it will probably fail
  # on Forge because of the symlink tree pointing into the cache:
  # MOE:end_strip

  # Note that the below is [""] for "", and e.g. ["x", ""] for "x:"
  # ("" is a valid entry to denote the current directory)
  pythonpath = options.pythonpath.split(os.pathsep)

  import_drop_prefixes = [
      p for p in options.import_drop_prefixes.split(os.pathsep) if p]

  python_version = tuple(map(int, options.python_version.split(".")))
  if len(python_version) != 2:
    log.error("--python_version must be <major>.<minor>")
    sys.exit(1)

  log.info("Process all: %s", src_out)
  for input_filename, output_filename in src_out:
    log.info("Process [1] %s => %s", input_filename, output_filename)
    process_one_file(input_filename, output_filename, options,
                     pythonpath, import_drop_prefixes, python_version)

  if len(src_out) > 1:
    # Do it once more, using any outputs that were produced the first time
    # TODO(pludemann): this is a moderately awful hack: it ensures that any
    #                  multually-dependent generated .pytd files have
    #                  been created, so any further import errors are
    #                  real import errors.
    log.info("Re-processing multiple files (%d)", len(src_out))
    log_level_tracker.clear()
    for input_filename, output_filename in src_out:
      log.info("Process [2] %s => %s", input_filename, output_filename)
      process_one_file(input_filename, output_filename, options,
                       pythonpath, import_drop_prefixes, python_version)

  if (options.irascible is not None and
      log_level_tracker.max_level >= LOG_LEVELS[options.irascible]):
    log.critical("Maximum log message %s >= %s",
                 logging.getLevelName(log_level_tracker.max_level),
                 logging.getLevelName(LOG_LEVELS[options.irascible]))
    sys.exit(1)


if __name__ == "__main__":
  main(sys.argv)
